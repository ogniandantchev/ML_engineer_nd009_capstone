{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "bda964c9c0a5cde453ef22334a7897a91e73e19b850bcb100e67a46c89d10a59"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Discussion, TODO, Cleanup and References\n",
    "\n",
    "---\n",
    "\n",
    "## Discussion\n",
    "\n",
    "+ The main goal was to learn how implement and deploy DeepAR+ model for time series forecast to AWS Amazon Forecast. \n",
    "\n",
    "+ The DeepAR+ model of Amazon Forecast (notebook 04) has RMSE of 2.806, while the custom Dilated Causal CNN (notebook 03) has an MSE 0.0037 (or RMSE = MSE **2 = 0.061).  Of course it is not fare to compare a model based on just one time series, to the multivariate custom model.\n",
    "\n",
    "+ the total cost of training and deploying the model at AWS Amazon Forecast was EUR 0.78 (USD 0.91)\n",
    "\n",
    "## TODO:\n",
    "\n",
    "+ implement a multivariate version of the predictor, based on the Amazon Forecast advanced examples [here](https://github.com/aws-samples/amazon-forecast-samples/tree/master/notebooks/advanced/Incorporating_Related_Time_Series_dataset_to_your_Predictor), and add the additional data from the originnal dataset -- athmospheric pressure and temperature for other cities in the region\n",
    "\n",
    "+ at the moment metric for the model in 02 is MAE, in 03 metrics are MSE and MAPE, while Amazon Forecast uses RMSE and WAPE.  need to have same for all 3 models.\n",
    "\n",
    "+ DeepAR+ of Amazon Forecast gives probabilistic Monte Carlo type evaluations, calculating P10, P50 and P90 -- the plot at the end of Notebook 04.  I.e., a statistical confidence level for an estimate. TODO: inderstand the concept and implement for the first two models.\n",
    "\n",
    "\n",
    "\n",
    "## Cleanup\n",
    "\n",
    "The cleanup procedure for the AWS resources follows closely the Amazon Forecast Tutorial here:\n",
    "\n",
    "https://github.com/aws-samples/amazon-forecast-samples/blob/master/notebooks/basic/Tutorial/4.Cleanup.ipynb\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "import sys\r\n",
    "import os\r\n",
    "import json\r\n",
    "import time\r\n",
    "\r\n",
    "import boto3\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import util"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Retrieve  shared variables from the earlier notebooks.\n",
    "%store -r"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# %store -r\n",
    "\n",
    "# Print your choices from first notebook\n",
    "print(f\"item_id = {item_id}\")\n",
    "print(f\"project = {PROJECT}\")\n",
    "print(f\"data_version = {DATA_VERSION}\")\n",
    "print(f\"Forecast length = {FORECAST_LENGTH}\")\n",
    "print(f\"Dataset frequency = {DATASET_FREQUENCY}\")\n",
    "print(f\"Timestamp format = {TIMESTAMP_FORMAT}\")\n",
    "print(f\"dataset_group_arn = {dataset_group_arn}\")\n",
    "print(f\"role_arn = {role_arn}\")\n",
    "%store -r bucket_name\n",
    "print(f\"bucket_name = {bucket_name}\")\n",
    "%store -r region\n",
    "print(f\"region = {region}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "item_id = Sofia\nproject = sof_temperature_forecast\ndata_version = 1\nForecast length = 72\nDataset frequency = H\nTimestamp format = yyyy-MM-dd hh:mm:ss\ndataset_group_arn = arn:aws:forecast:eu-central-1:574930355514:dataset-group/sof_temperature_forecast_1\nrole_arn = arn:aws:iam::574930355514:role/ForecastNotebookRole-Basic\nbucket_name = forecast-test-0\nregion = eu-central-1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "source": [
    "## NB: the below cells are not executed intentionally, to keep the AWS model active for the moment.\n",
    "---\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# connect to the Forecast APIs via the SDK.\r\n",
    "\r\n",
    "ession = boto3.Session(region_name= region) \r\n",
    "forecast = session.client(service_name= 'forecast') \r\n",
    "forecastquery = session.client(service_name= 'forecastquery')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "# Define the Things to Cleanup\r\n",
    "# In the previous notebooks several variables were stored at the end of each.  Now that they have been retrieved above, the cells below will delete the items that were created one at a time until all items that were created have been removed. \r\n",
    "# For a parent resource, all its child resources can be deleted using `delete_resource_tree` -- see AWS DeleteResourceTree API:\r\n",
    "# https://docs.aws.amazon.com/forecast/latest/dg/API_DeleteResourceTree.html\r\n",
    "# Bellow cell uses `delete_resource_tree` to delete the predictor resource and all its child resources such as Forecasts, PredictorBacktestExportJobs and ForecastExportJobs."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Delete predictor and all its child resources such as Forecasts, PredictorBacktestExportJobs and ForecastExportJobs \r\n",
    "util.wait_till_delete(lambda: forecast.delete_resource_tree(ResourceArn = predictor_arn_deep_ar))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Delete the target time series dataset import job\r\n",
    "util.wait_till_delete(lambda: forecast.delete_dataset_import_job(DatasetImportJobArn=ts_dataset_import_job_arn))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Delete the target time series dataset\r\n",
    "util.wait_till_delete(lambda: forecast.delete_dataset(DatasetArn=ts_dataset_arn))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Delete dataset group\r\n",
    "util.wait_till_delete(lambda: forecast.delete_dataset_group(DatasetGroupArn=dataset_group_arn))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Delete the files in S3\r\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(key).delete()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# IAM Role and Policy Cleanup\r\n",
    "# Remove the policies that were attached to a role and then to delete it. \r\n",
    "\r\n",
    "\r\n",
    "util.delete_iam_role( role_arn )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References\r\n",
    "\r\n",
    "\r\n",
    "1. Magnus Erik Hvass Pedersen, [TensorFlow-Tutorials](http://www.hvass-labs.org/)\r\n",
    "/ [GitHub repo](https://github.com/Hvass-Labs/TensorFlow-Tutorials) / [Videos on YouTube](https://www.youtube.com/playlist?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ)\r\n",
    "\r\n",
    "2. Ognian Dantchev, Multivariate Time Series Forecasting with Keras and TensorFlow, [GitHub repo](https://github.com/ogniandantchev/dilated_causal_cnn_time_series)\r\n",
    "\r\n",
    "3. Amazon Forecast resources, [AWS website](https://aws.amazon.com/forecast/resources/)\r\n",
    "\r\n",
    "4. Time Series Forecasting Principles with Amazon Forecast, [Technical Guide](https://d1.awsstatic.com/whitepapers/time-series-forecasting-principles-amazon-forecast.pdf)\r\n",
    "\r\n",
    "5. AWS Samples-- Amazon Forecast Samples [GitHub repo](https://github.com/aws-samples/amazon-forecast-samples)\r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ]
}